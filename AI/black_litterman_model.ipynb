{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Shikhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Shikhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shikhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shikhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_market_data(asset):\n",
    "    now = datetime.timestamp(datetime.now())\n",
    "    past = datetime.timestamp(datetime.now() - timedelta(days=31))\n",
    "    history_url = f\"https://api.coingecko.com/api/v3/coins/{asset}/market_chart/range?vs_currency=usd&from={past}&to={now}&precision=2\"\n",
    "    # cap_url = \"https://pro-api.coingecko.com/api/v3/global\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"CG-Ku3YXeJ8YooAqzJnb2G3VN9S\": asset\n",
    "    }\n",
    "\n",
    "    history_response = requests.get(history_url, headers=headers)\n",
    "    # cap_response = requests.get(cap_url, headers=headers)\n",
    "    data = history_response.json()['prices']\n",
    "    df = pd.DataFrame(data, columns=['timestamp','price'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = ['bitcoin', 'ethereum', 'binancecoin', 'cardano', 'ripple']\n",
    "# get the market data of the last 30 days\n",
    "data = {crypto: fetch_market_data(crypto) for crypto in cryptos}\n",
    "# Combine data into a single DataFrame\n",
    "merged_data = pd.concat([df['price'].rename(crypto) for crypto, df in data.items()], axis=1)\n",
    "\n",
    "merged_data.ffill(inplace=True)  # Forward fill to handle leading NaNs\n",
    "merged_data.bfill(inplace=True)  # Backward fill to handle trailing NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>ethereum</th>\n",
       "      <th>binancecoin</th>\n",
       "      <th>cardano</th>\n",
       "      <th>ripple</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-07-13 23:01:15.611</th>\n",
       "      <td>59468.70</td>\n",
       "      <td>3198.25</td>\n",
       "      <td>534.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-13 23:02:38.865</th>\n",
       "      <td>59468.70</td>\n",
       "      <td>3198.25</td>\n",
       "      <td>534.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-13 23:03:25.207</th>\n",
       "      <td>59468.70</td>\n",
       "      <td>3198.25</td>\n",
       "      <td>534.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-13 23:04:34.096</th>\n",
       "      <td>59468.70</td>\n",
       "      <td>3198.25</td>\n",
       "      <td>534.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-13 23:04:45.140</th>\n",
       "      <td>59468.70</td>\n",
       "      <td>3198.25</td>\n",
       "      <td>534.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-13 22:03:30.078</th>\n",
       "      <td>60634.62</td>\n",
       "      <td>2697.81</td>\n",
       "      <td>523.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-13 22:03:50.329</th>\n",
       "      <td>60634.62</td>\n",
       "      <td>2697.81</td>\n",
       "      <td>523.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-13 22:08:24.185</th>\n",
       "      <td>60634.62</td>\n",
       "      <td>2697.81</td>\n",
       "      <td>524.85</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-13 22:08:39.348</th>\n",
       "      <td>60930.71</td>\n",
       "      <td>2697.81</td>\n",
       "      <td>524.85</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-13 22:21:04.205</th>\n",
       "      <td>60930.71</td>\n",
       "      <td>2709.02</td>\n",
       "      <td>524.85</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3714 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          bitcoin  ethereum  binancecoin  cardano  ripple\n",
       "timestamp                                                                \n",
       "2024-07-13 23:01:15.611  59468.70   3198.25       534.52     0.44    0.53\n",
       "2024-07-13 23:02:38.865  59468.70   3198.25       534.52     0.44    0.53\n",
       "2024-07-13 23:03:25.207  59468.70   3198.25       534.52     0.44    0.53\n",
       "2024-07-13 23:04:34.096  59468.70   3198.25       534.52     0.44    0.53\n",
       "2024-07-13 23:04:45.140  59468.70   3198.25       534.52     0.44    0.53\n",
       "...                           ...       ...          ...      ...     ...\n",
       "2024-08-13 22:03:30.078  60634.62   2697.81       523.31     0.34    0.58\n",
       "2024-08-13 22:03:50.329  60634.62   2697.81       523.31     0.34    0.58\n",
       "2024-08-13 22:08:24.185  60634.62   2697.81       524.85     0.34    0.58\n",
       "2024-08-13 22:08:39.348  60930.71   2697.81       524.85     0.34    0.58\n",
       "2024-08-13 22:21:04.205  60930.71   2709.02       524.85     0.34    0.58\n",
       "\n",
       "[3714 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the log returns\n",
    "returns = np.log(merged_data / merged_data.shift(1)).dropna()\n",
    "\n",
    "# Calculate the mean returns\n",
    "mean_returns = returns.mean()\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text\n",
    "\n",
    "def get_sentiment(tweets):\n",
    "    scores = []\n",
    "    for tweet in tweets:\n",
    "            processed_tweet = preprocess_text(tweet)\n",
    "            score = SentimentIntensityAnalyzer().polarity_scores(processed_tweet)\n",
    "            scores.append(score['compound'])\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis on the coin tweets\n",
    "# example tweets to demonstrate the sentiment analysis\n",
    "tweets = {\n",
    "        'bitcoin': [\"Lately, Bitcoin has been outperforming expectations. Positive outlook ahead. #BTC #investing\",\n",
    "                    \"BTC is on the rise again! Love seeing this kind of upward momentum. #Bitcoin #crypto\",\n",
    "                    \"Bitcoin has been doing incredibly well this month. Definitely seeing some promising gains. #BTC #cryptogains\"],\n",
    "          'ethereum': [\"Ethereumâ€™s DeFi ecosystem is thriving! $ETH to $5k might happen sooner than we think. #Ethereum #ETH #DeFi\",\n",
    "                    \"Ethereumâ€™s smart contracts are transforming industries. $ETH is a must-have in any portfolio! #Ethereum #ETH #blockchain\"],\n",
    "          'binancecoin': [\"Binance Coin is struggling big time... Regulatory concerns are dragging it down. #BNB #crypto\", \n",
    "                        \"Major FUD around Binance Coin lately. This dip looks like it might be the start of something worse. ðŸ˜Ÿ #BNB #cryptomarket\",\n",
    "                        \"Lately, BNB has been a disappointment. Negative trends are worrying. #BinanceCoin #crypto\"],\n",
    "          'cardano': [\"Cardanoâ€™s hype is fading fast. Delays and broken promises are killing confidence. #Cardano #ADA #crypto\",\n",
    "                    \"Cardano is stalling. The lack of progress is getting frustrating. ðŸ˜• #ADA #cryptomarket\"],\n",
    "          'ripple': [\"Ripple's situation is neither positive nor negative, just holding steady for now. #XRP #crypto\",\n",
    "                        \"Ripple is just there, not much change. No major positive or negative trends. #XRP #cryptomarket\"]\n",
    "          }\n",
    "\n",
    "scores = {}\n",
    "for asset in cryptos:\n",
    "        scores[asset] = get_sentiment(tweets[asset])\n",
    "\n",
    "# investor views are calculated using sentiment analysis\n",
    "Q = np.zeros((math.comb(len(cryptos),2),))\n",
    "P = np.zeros((math.comb(len(cryptos),2), len(cryptos)))\n",
    "omega = np.diag([0.0001]*Q.shape[0])\n",
    "view = 0\n",
    "for i in range(len(cryptos)):\n",
    "        for j in range(i+1,len(cryptos)):\n",
    "                P[view,i] = int(np.sign(scores[cryptos[i]] - scores[cryptos[j]]))\n",
    "                P[view,j] = int(np.sign(scores[cryptos[j]] - scores[cryptos[i]]))\n",
    "                Q[view] = abs(scores[cryptos[i]] - scores[cryptos[j]])/10\n",
    "                view = view + 1\n",
    "                assert np.all(np.sum(P, 1) == 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market weights and equilibrium returns\n",
    "market_weights = np.array([0.6, 0.3, 0.1, 0.2, 0.1])  # Example weights - In real scenario they will be calculated based on market cap of each coin\n",
    "tau = 0.025\n",
    "market_equilibrium_returns = np.dot(cov_matrix, market_weights) / tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black-Litterman Expected Returns\n",
    "M_inverse = np.linalg.inv(tau * cov_matrix)\n",
    "BL_returns = np.linalg.inv(M_inverse + np.dot(np.dot(P.T, np.linalg.inv(omega)), P)).dot(\n",
    "    np.dot(M_inverse, market_equilibrium_returns) + np.dot(np.dot(P.T, np.linalg.inv(omega)), Q))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean-Variance Optimization (MVO) using Black-Litterman returns\n",
    "def portfolio_variance(weights, cov_matrix):\n",
    "    return weights.T @ cov_matrix @ weights\n",
    "\n",
    "def portfolio_return(weights, returns):\n",
    "    return np.dot(weights, returns)\n",
    "\n",
    "def mvo_optimizer(expected_returns, cov_matrix):\n",
    "    num_assets = len(expected_returns)\n",
    "    args = (expected_returns,cov_matrix)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in range(num_assets))\n",
    "    initial_guess = num_assets * [1. / num_assets,]\n",
    "\n",
    "    def neg_sharpe_ratio(weights, expected_returns, cov_matrix):\n",
    "        returns = portfolio_return(weights, expected_returns)\n",
    "        variance = portfolio_variance(weights, cov_matrix)\n",
    "        return -returns / np.sqrt(variance)\n",
    "\n",
    "    result = minimize(neg_sharpe_ratio, initial_guess, args=args,\n",
    "                      method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights are: [7.08838015e-01 2.52306242e-01 0.00000000e+00 2.66713734e-17\n",
      " 3.88557431e-02]\n"
     ]
    }
   ],
   "source": [
    "optimal_weights = mvo_optimizer(BL_returns, cov_matrix)\n",
    "assert sum(optimal_weights) == 1.0\n",
    "print(\"Optimal Weights are: \"+str(optimal_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aether",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
